{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYCUyse9KroUhzn/pmc0Gu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youngmi-Park/pytorch-study/blob/main/Basic/Pytorch_Basic1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basic"
      ],
      "metadata": {
        "id": "cwbNB5bw7IFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##. 1. Import packages\n",
        "필요한 패키지를 설치하고 import한다.\n",
        "colab에서 pytorch를 사용하려면 런타임 유형을 변경해야한다.\n",
        "타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴 [런타임]→[런타임유형변경]→[하드웨어가속기]→[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 한다."
      ],
      "metadata": {
        "id": "Qh-Cxvu17PeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k5rZZNrui_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44818c34-894d-494a-fb7c-2cd9c11cfdbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 벡터, 행렬, 텐서\n",
        "- 벡터(Vector): 1차원으로 구성된 값\n",
        "- 행렬(Matrix): 2차원으로 구성된 값\n",
        "- 텐서(Tensor): 3차원으로 구성된 값\n",
        "\n",
        "4차원 이상 부터는 3차원의 텐서를 위로 쌓아올린 모습으로 볼 수 있다.\n",
        "또한 주로 3차원 이상을 텐서라고 하긴 하지만, 1차원 벡터나 2차원인 행렬도 텐서라고 표현하기도 한다.\n",
        "- 벡터 = 1차원 텐서, 2차원 행렬 = 2차원 텐서. 그리고 3차원 텐서, 4차원 텐서, 5차원 텐서 등...\n",
        "\n",
        "PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타낸다.\n",
        "\n",
        "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사하다. \n",
        "\n",
        "\n",
        "-  2D Tensor(Typical Simple Setting)\n",
        "\n",
        "  - |t| = (batch size, dim)\n",
        "\n",
        "- 3D Tensor(Typical Computer Vision) - 비전 분야에서의 3차원 텐서\n",
        "\n",
        "  - |t| = (batch size, width, height)\n",
        "\n",
        "* 3D Tensor(Typical Natural Language Processing) - NLP 분야에서의 3차원 텐서\n",
        "\n",
        "  - |t| = (batch size, length, dim)"
      ],
      "metadata": {
        "id": "1BTtkBUa8Z-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Pytorch 텐서 선언하기\n",
        "직접 생성하기"
      ],
      "metadata": {
        "id": "QZuce1jh-nsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.]) # 1D Tensor(vector)\n",
        "t2 = torch.FloatTensor([[1, 2],[1, 2]])\n",
        "print(t1)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxdymoCd-nDW",
        "outputId": "2c40be71-cc15-4828-8468-34909fdd2ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
            "tensor([[1., 2.],\n",
            "        [1., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터로 부터 생성하기"
      ],
      "metadata": {
        "id": "MkpsoAGT_Krk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x = torch.tensor(data)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlFx4q12_KQv",
        "outputId": "39b6081f-ab1a-47b0-ef89-042e37f3326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array(data) \n",
        "x = torch.from_numpy(np_array)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grfx57oK7xMP",
        "outputId": "e92f6bd9-a6f3-4be1-91d9-bf3edf130f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor에서 Numpy array로 변환하기"
      ],
      "metadata": {
        "id": "vtt99SEB_dX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5wABjEI_etF",
        "outputId": "47ec7752-8faa-4b9a-8c0b-becb3d447ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ],
      "metadata": {
        "id": "H8ZNdhENAaVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x) # x와 모양은 같고 원소가 1\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype=torch.float) # x와 모양은 같고 원소가 랜덤\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D83149Q-AYR9",
        "outputId": "bd5ef092-125e-49a3-ca11-06298fe8e8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9781, 0.2812],\n",
            "        [0.1179, 0.1258]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "주어진 shape으로 초기화하기"
      ],
      "metadata": {
        "id": "kBkSd3Z9AxdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (1,4)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toAuiysRAw-T",
        "outputId": "8c1b742e-3871-449a-9ee2-f1551cb389d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.4701, 0.7573, 0.8374, 0.5718]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 텐서의 속성 - 차원, 크기, 자료형\n",
        "- dim(): 텐서의 차원\n",
        "- shape(), size(): 텐서의 모양 및 크기\n",
        "- datatype(): 텐서의 자료형"
      ],
      "metadata": {
        "id": "rQFeKhhM_9Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dim of tensor: {t1.dim()}\")  # rank. 즉, 차원, 1차원\n",
        "print(f\"Shape of tensor: {t1.shape}\")  # shape, 7개 원소\n",
        "print(f\"Shape of tensor: {t1.size()}\") # shape\n",
        "print(f\"Datatype of tensor: {t1.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGNmNBI1_8pm",
        "outputId": "eaba694d-d2ab-4286-b9d0-8939978b17ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dim of tensor: 1\n",
            "Shape of tensor: torch.Size([7])\n",
            "Shape of tensor: torch.Size([7])\n",
            "Datatype of tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dim of tensor: {t2.dim()}\")  # rank. 즉, 차원, 1차원\n",
        "print(f\"Shape of tensor: {t2.shape}\")  # shape, 7개 원소\n",
        "print(f\"Shape of tensor: {t2.size()}\") # shape\n",
        "print(f\"Datatype of tensor: {t2.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlKXwki1AGx9",
        "outputId": "1f9e7c10-94ee-40e0-bc26-ac03990fd2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dim of tensor: 2\n",
            "Shape of tensor: torch.Size([2, 2])\n",
            "Shape of tensor: torch.Size([2, 2])\n",
            "Datatype of tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KifxmJZVCCpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "t1 = t1.to(device)\n",
        "print(f\"Device tensor is stored on: {t1.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVE7KZ6BAIQ5",
        "outputId": "a4f5a8d8-bdbc-4909-acdb-f6d0d11913f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 텐서의 연산\n"
      ],
      "metadata": {
        "id": "gcAkJdckCb79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyuoLniOCK_U",
        "outputId": "9c4bb0c5-de8b-4cd1-9ebb-51bb6f140e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 텐서 합치기(Concatenate)"
      ],
      "metadata": {
        "id": "3PIPnEhlDKOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0) # 가장 큰 차원에서 부터 0, 행\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq2jI5JcCkfY",
        "outputId": "f0d52762-497e-457a-9951-aa9fb4ed2844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43zvqMgkDUKB",
        "outputId": "2391c721-7238-4376-a11a-ab9dca500e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*이탤릭체 텍스트*### 2) 텐서 곱하기 \n",
        "### - Matrix Multiplication\n",
        "텐서를 곱하는 방법 중에서 행렬곱 연산"
      ],
      "metadata": {
        "id": "wlvvV2XXDmFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o42PSI6DYWa",
        "outputId": "67e25eb5-5dd3-455e-c509-e4764c032699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Element-wise Product\n",
        "행렬의 요소별 곱 연산"
      ],
      "metadata": {
        "id": "XU5y5I1KD87n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVXO4T5iD63U",
        "outputId": "de019583-fdbe-4584-be6b-955a3db66887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) 평균 (Mean)\n",
        "기본적으로 모든 원소의 평균을 구한다. dim. 즉, 차원(dimension)을 인자로 주는 경우 해당 차원을 제거한다는 의미이다."
      ],
      "metadata": {
        "id": "HMJ37k2xE66v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEaQGL2fFkJN",
        "outputId": "9576c542-c53e-4e10-938d-619e40b4b3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [1., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2.mean()) # 전체원소의 평균\n",
        "print(t2.mean(dim=0)) # 첫 번째 차원 제거, 0은 행을 의미, 행을 제거함, 열에 대한 평균\n",
        "print(t2.mean(dim=1)) # 두 번째 차원 제거, 1은 열을 의미, 열을 제거함, 행에 대한 평균\n",
        "print(t2.mean(dim=-1)) # 마지막 차원 제거, 열을 제거함, 행에 대한 평균"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiwHVydZEtHy",
        "outputId": "75a91306-9c15-43bc-efa7-87b1191ef615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5000)\n",
            "tensor([1., 2.])\n",
            "tensor([1.5000, 1.5000])\n",
            "tensor([1.5000, 1.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) 덧셈 (Sum)\n",
        "평균과 연산 방법이나 인자가 의미하는 바가 동일하다."
      ],
      "metadata": {
        "id": "EArjs3rtGZxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2.sum()) # 전체원소의 덧셈셈\n",
        "print(t2.sum(dim=0)) # 첫 번째 차원 제거, 0은 행을 의미, 행을 제거함, 열에 대한 덧셈\n",
        "print(t2.sum(dim=1)) # 두 번째 차원 제거, 1은 열을 의미, 열을 제거함, 행에 대한 덧셈\n",
        "print(t2.sum(dim=-1)) # 마지막 차원 제거, 열을 제거함, 행에 대한 덧셈"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdNNlt2PFdz_",
        "outputId": "5ae8834c-c34f-4953-f540-55d9a8221d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.)\n",
            "tensor([2., 4.])\n",
            "tensor([3., 3.])\n",
            "tensor([3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) 최대(Max), 아그맥스(ArgMax)\n",
        "- 최대: 원소의 최댓값을 리턴\n",
        "- 아그맥스: 최댓값을 가진 원소의 인덱스를 리턴"
      ],
      "metadata": {
        "id": "Lto1PqmEG1fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFwAxJdJGwz-",
        "outputId": "d4610705-5bb5-4759-e1d5-210603971db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.max())\n",
        "print(t.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtgWdapnHGNu",
        "outputId": "d8abb765-7da4-4ee0-d942-e4d822adddf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dim = 0을 인자로 주면 첫번째 차원을 제거한다\n",
        "행의 차원을 제거한다는 의미이므로 (1, 2) 텐서를 만든다. 그리고 max 에 dim인자를 주면 argmax도 함께 리턴한다.\n",
        "첫번째 열에서 0번 인덱스는 1, 1번 인덱스는 3이고 두번째 열에서 0번 인덱스는 2, 1번 인덱스는 4이다.\n",
        "다시 말해 3과 4의 인덱스는 [1, 1]이다."
      ],
      "metadata": {
        "id": "f54oH5ZhHdPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.max(dim=0)) # Returns two values: max and argmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1h2SuPgHHjK",
        "outputId": "fe020863-9b8f-4dcd-db71-e39b72431681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([3., 4.]),\n",
            "indices=tensor([1, 1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) 브로드캐스팅(Broadcasting)\n",
        "두 행렬을 연산할 때 덧셈과 뺄셈은 행렬의 크기가 같아야하고 곱셈에서는 A, B를 곱할 때 A의 마지막 차원과 B의 첫번째 차원이 일치해야한다.\n",
        "\n",
        "하지만, 딥러닝을 하다보면 크기가 다른 행렬 또는 텐서에 대해서 연산을 수행해야하는 경우가 생긴다. 이를 위해서 자동으로 크기를 맞춰서 연산을 수행하는 것이 브로드캐스팅이라는 기능이다."
      ],
      "metadata": {
        "id": "a1c3cnORIE-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터와 스칼라의 덧셈 연산\n",
        "m1 = torch.FloatTensor([1, 2])\n",
        "m2 = torch.FloatTensor([3]) # 스칼라, [3] → [3, 3]\n",
        "print(m1 + m2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCMHHhdZHa-u",
        "outputId": "43008a7d-676f-4ff4-f258-ebc66e6e415c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모양이 다른 두 벡터 연산\n",
        "m1 = torch.FloatTensor([1, 2]) #  →  [[1, 2], [1, 2]]\n",
        "m2 = torch.FloatTensor([[3], [4]]) #  → [[3, 3], [4, 4]]\n",
        "print(m1 + m2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGOpJ_60I9p4",
        "outputId": "4af26b03-d98c-4d5e-e133-ca67de28c32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 5.],\n",
            "        [5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "브로드캐스팅은 편리하지만, 자동으로 실행되는 기능이므로 사용자 입장에서 굉장히 주의해서 사용해야 한다. 예를 들어 A 텐서와 B 텐서가 있을 때, 사용자는 이 두 텐서의 크기가 같다고 착각하고 덧셈 연산을 수행했다고 가정했을 때 실제로 이 두 텐서의 크기는 달랐고 브로드캐스팅이 수행되어 덧셈 연산이 수행되었다. 만약, 두 텐서의 크기가 다르다고 에러를 발생시킨다면 사용자는 이 연산이 잘못되었음을 바로 알 수 있지만 브로드캐스팅은 자동으로 수행되므로 사용자는 나중에 원하는 결과가 나오지 않았더라도 어디서 문제가 발생했는지 찾기가 굉장히 어려울 수 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "wknOULglJjNM"
      }
    }
  ]
}